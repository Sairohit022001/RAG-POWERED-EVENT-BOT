{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWvu85HEvSWEJh3S4jToUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sairohit022001/RAG-POWERED-EVENT-BOT/blob/main/RAG_POWERED_EVENT_ASSISTANT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8_Z_xjWdvL8s"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from agenda import show_agenda\n",
        "from matching import show_matching\n",
        "from directions import show_directions\n",
        "from recommendations import show_recommendations\n",
        "from lunch_timer import show_lunch_timer\n",
        "from feedback import show_feedback\n",
        "from rag_agent import show_rag_interface\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(page_title=\"Event Bot\", page_icon=\"⚙︎\")\n",
        "\n",
        "# Sidebar Navigation\n",
        "option = st.sidebar.selectbox(\"Choose an option\", [\n",
        "    \"Agenda\",\n",
        "    \"Matching\",\n",
        "    \"Recommendations\",\n",
        "    \"Directions\",\n",
        "    \"Lunch Timer\",\n",
        "    \"Event Feedback\",\n",
        "    \"Event Assistant\"\n",
        "])\n",
        "\n",
        "# Only show welcome message on Agenda page\n",
        "if option == \"Agenda\":\n",
        "    st.title(\"⚙︎ WELCOME TO RAG POWERED EVENT ASSISTANT\")\n",
        "    st.markdown(\"\"\"\n",
        "    This is your **Build with AI Workshop Event Bot** — Your Smart Assistant for Event Info, Schedule & Updates\n",
        "    1. ✅ Agenda Details\n",
        "    2. 👥 Participant Matching Engine (Resume-Based)\n",
        "    3. 📌 Session recommendations\n",
        "    4. 🗺 Washroom directions\n",
        "    5. ⏱ Real-time lunch countdown\n",
        "    6. 📝 Session Feedback (Conversational)\n",
        "    7. 🤖 Event Assistant (Chat with your Event)\n",
        "    \"\"\")\n",
        "    show_agenda()\n",
        "\n",
        "elif option == \"Matching\":\n",
        "    show_matching()\n",
        "elif option == \"Recommendations\":\n",
        "    show_recommendations()\n",
        "elif option == \"Directions\":\n",
        "    show_directions()\n",
        "elif option == \"Lunch Timer\":\n",
        "    show_lunch_timer()\n",
        "elif option == \"Event Feedback\":\n",
        "    show_feedback()\n",
        "elif option == \"Event Assistant\":\n",
        "    show_rag_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOIVQu5MNUOX",
        "outputId": "508a72f6-97c0-4b3d-ec2c-aa2902d5ba13"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer , util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "SythbmZTxJMn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile agenda.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def show_agenda():\n",
        "\n",
        "\n",
        "    agenda = {\n",
        "       \"10:00 - 11:00 AM\": \"Hands On Workshop: Automation using Claude and MCP Server - Vijender P, Alumnx\",\n",
        "       \"11:00 - 12:00 PM\": \"Hands On Workshop: Agentic AI - Jitendra Gupta (Google Developer Expert)\",\n",
        "       \"12:00 - 1:00 PM\": \"Industry Connect Session - Ravi Babu, Apex Cura Healthcare\",\n",
        "       \"1:00 - 2:00 PM\": \"Lunch\",\n",
        "       \"2:00 - 3:00 PM\": \"Hands On Workshop: Build an Event Bot using RAG - Vishvas Dubey, TCS\",\n",
        "       \"3:00 - 3:30 PM\": \"Industry Application of AI: Building Multi AI Agents - Surendranath Reddy, QAPilot\",\n",
        "       \"3:30 - 4:00 PM\": \"Workshop: Building Multi AI Agents - Mahidhar, NexusHub\"\n",
        "    }\n",
        "\n",
        "    st.header(\" Meeting Agenda\")\n",
        "    for time, event in agenda.items():\n",
        "        st.markdown(f\"**{time}**: {event}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTeYgqCfdXEB",
        "outputId": "40f914e6-626b-4856-c2ee-d34381447532"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting agenda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matching.py\n",
        "\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "if \"resumes\" not in st.session_state:\n",
        "    st.session_state.resumes = {}\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def show_matching():\n",
        "    st.sidebar.header(\"👥 Participant Matching Engine (Resume-Based)\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload your resume (PDF only)\", type=[\"pdf\"])\n",
        "    if uploaded_file is not None:\n",
        "        resume_text = extract_text_from_pdf(uploaded_file)\n",
        "        user_id = f\"user_{len(st.session_state.resumes)+1}\"\n",
        "        st.session_state.resumes[user_id] = resume_text\n",
        "        st.success(\"Resume uploaded and processed!\")\n",
        "\n",
        "        st.subheader(\"Your Resume Preview\")\n",
        "        st.text_area(\"Resume Content\", resume_text, height=200)\n",
        "\n",
        "    if len(st.session_state.resumes) > 1:\n",
        "        st.subheader(\"Matching Participants\")\n",
        "        texts = list(st.session_state.resumes.values())\n",
        "        user_ids = list(st.session_state.resumes.keys())\n",
        "\n",
        "        vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "        similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "        for idx, user_id in enumerate(user_ids):\n",
        "            st.write(f\"Matches for **{user_id}**:\")\n",
        "            sim_scores = similarity_matrix[idx]\n",
        "            sim_scores[idx] = -1\n",
        "            top_matches = sim_scores.argsort()[-2:][::-1]\n",
        "\n",
        "            for match_idx in top_matches:\n",
        "                st.write(f\"- {user_ids[match_idx]} (Similarity: {sim_scores[match_idx]:.2f})\")\n",
        "            st.write(\"---\")\n",
        "    else:\n",
        "        st.info(\"Upload at least 2 resumes to see matching results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvx3YlCk_znC",
        "outputId": "388a59de-dd80-4c51-8ddf-7a63866babd2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matching.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile directions.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def show_directions():\n",
        "    st.header(\"🗺 Washroom Directions\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "     **Venue Layout**:\n",
        "    -  Ground Floor:\n",
        "        - 🚻 Washroom near Registration Desk\n",
        "        - 🚺 Women’s Washroom next to Conference Room A\n",
        "    -  First Floor:\n",
        "        - 🚻 Common Washroom near Workshop Hall\n",
        "        - ♿ Accessible Washroom at the stairway entrance\n",
        "\n",
        "    🔄 Ask any volunteer if you feel lost – they’re happy to guide you!\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLHCK3XWe30L",
        "outputId": "2c4c3a02-f0ae-401d-ce06-efee5936efd4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting directions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile recommendations.py\n",
        "import streamlit as st\n",
        "\n",
        "def show_recommendations():\n",
        "    st.header(\"📌 Session Recommendations\")\n",
        "    st.write(\"Based on your interests, here are some sessions we think you’ll love:\")\n",
        "    recommendations = [\n",
        "        \"🤖 Hands On Workshop: Automation using Claude and MCP Server\",\n",
        "        \"🧠 Agentic AI - Jitendra Gupta (Google Developer Expert)\",\n",
        "        \"🤝 Industry Application of AI: Building Multi AI Agents - Surendranath Reddy\",\n",
        "        \"💡 Workshop: Building Multi AI Agents - Mahidhar, NexusHub\"\n",
        "    ]\n",
        "    for session in recommendations:\n",
        "        st.markdown(f\"- {session}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhYjbDhcbVVG",
        "outputId": "6cb323f7-5ffc-464f-f6f7-6385c6c5b706"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting recommendations.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lunch_timer.py\n",
        "import streamlit as st\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def show_lunch_timer():\n",
        "    st.header(\"⏱️ Real-time Lunch Countdown\")\n",
        "\n",
        "    lunch_end_time = datetime(year=2025, month=5, day=18, hour=13, minute=0, second=0)\n",
        "\n",
        "\n",
        "    if datetime.now() > lunch_end_time:\n",
        "        st.success(\"🍽️ Lunch time is over!\")\n",
        "        return\n",
        "\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    while True:\n",
        "        now = datetime.now()\n",
        "        remaining = lunch_end_time - now\n",
        "\n",
        "        if remaining.total_seconds() <= 0:\n",
        "            placeholder.success(\"🍽️ Lunch time is over!\")\n",
        "            break\n",
        "\n",
        "        mins, secs = divmod(int(remaining.total_seconds()), 60)\n",
        "        placeholder.markdown(f\"Time remaining for lunch: **{mins} minutes {secs} seconds**\")\n",
        "\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJG642dIoebq",
        "outputId": "6d2864f5-0754-4555-dc34-e21266df15f5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lunch_timer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feedback.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "feedback_list = []\n",
        "\n",
        "def show_feedback():\n",
        "    st.header(\"📝 Session Feedback\")\n",
        "\n",
        "    name = st.text_input(\"Your Name\")\n",
        "    session = st.selectbox(\"Session\", [\"Workshop 1\", \"Workshop 2\", \"Industry Talk\", \"Lunch\"])\n",
        "    rating = st.slider(\"Rate this session (1-5)\", 1, 5, 3)\n",
        "    comments = st.text_area(\"Additional Comments\")\n",
        "\n",
        "    if st.button(\"Submit Feedback\"):\n",
        "        if not name or not comments:\n",
        "            st.warning(\"Please fill in your name and comments.\")\n",
        "        else:\n",
        "            feedback = {\n",
        "                \"name\": name,\n",
        "                \"session\": session,\n",
        "                \"rating\": rating,\n",
        "                \"comments\": comments,\n",
        "            }\n",
        "            feedback_list.append(feedback)\n",
        "            st.success(\"Thank you for your feedback!\")\n",
        "\n",
        "    if feedback_list:\n",
        "        st.subheader(\"Previous Feedback\")\n",
        "        for fb in feedback_list:\n",
        "            st.markdown(f\"**{fb['name']}** on *{fb['session']}* rated: {fb['rating']}/5\")\n",
        "            st.write(fb['comments'])\n",
        "            st.write(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UWE5lCukrp7",
        "outputId": "f696e592-08b1-496a-bcff-40a8ba289a82"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feedback.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit faiss-cpu sentence-transformers transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tkPwl-6ykSn",
        "outputId": "6ab6d3a0-d297-4bcc-d0b1-369a7c35230a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuzZZ9zX4mH",
        "outputId": "70c6406c-2389-4bb6-a1b6-d61a5ff862cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.6)\n",
            "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250327)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rag_agent.py\n",
        "\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "generator = pipeline('text2text-generation', model='t5-small')\n",
        "\n",
        "embedding_dim = 384\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "documents = []\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, max_length=500):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = []\n",
        "    chunk = \"\"\n",
        "    for sent in sentences:\n",
        "        if len(chunk) + len(sent) < max_length:\n",
        "            chunk += sent + '. '\n",
        "        else:\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sent + '. '\n",
        "    if chunk:\n",
        "        chunks.append(chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "def add_document(file):\n",
        "    text = extract_text_from_pdf(file)\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = embedding_model.encode(chunks)\n",
        "    for emb, chunk in zip(embeddings, chunks):\n",
        "        index.add(np.array([emb]))\n",
        "        documents.append(chunk)\n",
        "\n",
        "def retrieve(query, top_k=3):\n",
        "    query_emb = embedding_model.encode([query])\n",
        "    D, I = index.search(np.array(query_emb), top_k)\n",
        "    results = [documents[i] for i in I[0] if i < len(documents)]\n",
        "    return results\n",
        "\n",
        "def generate_answer(retrieved_chunks, query):\n",
        "    context = \" \".join(retrieved_chunks)\n",
        "    input_text = f\"summarize: {context} question: {query}\"\n",
        "    output = generator(input_text, max_length=150)[0]['generated_text']\n",
        "    return output\n",
        "\n",
        "def show_rag_interface():\n",
        "    st.sidebar.header(\"📚 RAG Powered Event Assistant\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload\", type=['pdf'])\n",
        "    if uploaded_file is not None:\n",
        "        add_document(uploaded_file)\n",
        "        st.success(\"Document uploaded and indexed!\")\n",
        "\n",
        "    query = st.text_input(\"Ask anything:\")\n",
        "\n",
        "    if st.button(\"Get Answer\") and query:\n",
        "        if len(documents) == 0:\n",
        "            st.warning(\"Please upload notes first!\")\n",
        "        else:\n",
        "            retrieved = retrieve(query)\n",
        "            answer = generate_answer(retrieved, query)\n",
        "            st.markdown(\"**Answer:**\")\n",
        "            st.write(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myKlO9EKlnAz",
        "outputId": "51ee4d78-eacd-4107-b973-282e64022aac"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rag_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ngrok authtoken 2xAMlsU2bxIRl7KmMZbHhz7gtnA_2gRj1UMqL13VFrSrKzbaT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3vcQ1uwV1y",
        "outputId": "d77ce854-3cc4-4bca-8723-56510ec10f06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Kill previous tunnels\n",
        "!pkill streamlit\n",
        "\n",
        "# Open tunnel\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "\n",
        "print(f\"🔗 Streamlit app URL: {public_url}\")\n",
        "\n",
        "# Run Streamlit app\n",
        "!streamlit run app.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDMRE8Yw5XO",
        "outputId": "b92b3830-2f67-47cd-b82a-a33d4ab58f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Streamlit app URL: NgrokTunnel: \"https://18cf-35-227-117-103.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.117.103:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-05-16 15:24:57.905528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747409097.937466   24865 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747409097.947135   24865 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Device set to use cpu\n",
            "2025-05-16 15:25:06.462 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "dT3ZQG5dW3yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktLrUTuwf_gg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}