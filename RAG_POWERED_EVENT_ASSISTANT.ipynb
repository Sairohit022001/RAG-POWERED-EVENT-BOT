{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPWOHlCalpnS/k+zDsxidaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sairohit022001/RAG-POWERED-EVENT-BOT/blob/main/RAG_POWERED_EVENT_ASSISTANT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Z_xjWdvL8s"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from agenda import show_agenda\n",
        "from matching import show_matching\n",
        "from directions import show_directions\n",
        "from recommendations import show_recommendations\n",
        "from lunch_timer import show_lunch_timer\n",
        "from feedback import show_feedback\n",
        "from rag_agent import show_rag_interface\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(page_title=\"Event Bot\", page_icon=\"âš™ï¸\")\n",
        "\n",
        "# Sidebar Navigation\n",
        "option = st.sidebar.selectbox(\"Choose an option\", [\n",
        "    \"Agenda\",\n",
        "    \"Matching\",\n",
        "    \"Recommendations\",\n",
        "    \"Directions\",\n",
        "    \"Lunch Timer\",\n",
        "    \"Event Feedback\",\n",
        "    \"Event Assistant\"\n",
        "])\n",
        "\n",
        "# Only show welcome message on Agenda page\n",
        "if option == \"Agenda\":\n",
        "    st.title(\"âš™ï¸ WELCOME TO RAG POWERED EVENT ASSISTANT\")\n",
        "    st.markdown(\"\"\"\n",
        "    This is your **Build with AI Workshop Event Bot** â€” Your Smart Assistant for Event Info, Schedule & Updates\n",
        "    1. âœ… Agenda Details\n",
        "    2. ğŸ‘¥ Participant Matching Engine (Resume-Based)\n",
        "    3. ğŸ“Œ Session recommendations\n",
        "    4. ğŸ—º Washroom directions\n",
        "    5. â± Real-time lunch countdown\n",
        "    6. ğŸ“ Session Feedback (Conversational)\n",
        "    7. ğŸ¤– Event Assistant (Chat with your Event)\n",
        "    \"\"\")\n",
        "    show_agenda()\n",
        "\n",
        "elif option == \"Matching\":\n",
        "    show_matching()\n",
        "elif option == \"Recommendations\":\n",
        "    show_recommendations()\n",
        "elif option == \"Directions\":\n",
        "    show_directions()\n",
        "elif option == \"Lunch Timer\":\n",
        "    show_lunch_timer()\n",
        "elif option == \"Event Feedback\":\n",
        "    show_feedback()\n",
        "elif option == \"Event Assistant\":\n",
        "    show_rag_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOIVQu5MNUOX",
        "outputId": "fe5f774b-d186-4d69-f7d5-e0b02d890a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import streamlit as st\n",
        "from sentence_transformers import SentenceTransformer , util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SythbmZTxJMn",
        "outputId": "97c09415-9cb4-4654-fe65-500678e6e3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile agenda.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def show_agenda():\n",
        "\n",
        "\n",
        "    agenda = {\n",
        "       \"10:00 - 11:00 AM\": \"Hands On Workshop: Automation using Claude and MCP Server - Vijender P, Alumnx\",\n",
        "       \"11:00 - 12:00 PM\": \"Hands On Workshop: Agentic AI - Jitendra Gupta (Google Developer Expert)\",\n",
        "       \"12:00 - 1:00 PM\": \"Industry Connect Session - Ravi Babu, Apex Cura Healthcare\",\n",
        "       \"1:00 - 2:00 PM\": \"Lunch\",\n",
        "       \"2:00 - 3:00 PM\": \"Hands On Workshop: Build an Event Bot using RAG - Vishvas Dubey, TCS\",\n",
        "       \"3:00 - 3:30 PM\": \"Industry Application of AI: Building Multi AI Agents - Surendranath Reddy, QAPilot\",\n",
        "       \"3:30 - 4:00 PM\": \"Workshop: Building Multi AI Agents - Mahidhar, NexusHub\"\n",
        "    }\n",
        "\n",
        "    st.header(\" Meeting Agenda\")\n",
        "    for time, event in agenda.items():\n",
        "        st.markdown(f\"**{time}**: {event}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTeYgqCfdXEB",
        "outputId": "c6f1406a-44b6-493d-ce01-46c2c8b75e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting agenda.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matching.py\n",
        "\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "if \"resumes\" not in st.session_state:\n",
        "    st.session_state.resumes = {}\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def show_matching():\n",
        "    st.sidebar.header(\"ğŸ‘¥ Participant Matching Engine (Resume-Based)\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload your resume (PDF only)\", type=[\"pdf\"])\n",
        "    if uploaded_file is not None:\n",
        "        resume_text = extract_text_from_pdf(uploaded_file)\n",
        "        user_id = f\"user_{len(st.session_state.resumes)+1}\"\n",
        "        st.session_state.resumes[user_id] = resume_text\n",
        "        st.success(\"Resume uploaded and processed!\")\n",
        "\n",
        "        st.subheader(\"Your Resume Preview\")\n",
        "        st.text_area(\"Resume Content\", resume_text, height=200)\n",
        "\n",
        "    if len(st.session_state.resumes) > 1:\n",
        "        st.subheader(\"Matching Participants\")\n",
        "        texts = list(st.session_state.resumes.values())\n",
        "        user_ids = list(st.session_state.resumes.keys())\n",
        "\n",
        "        vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "        tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "        similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "        for idx, user_id in enumerate(user_ids):\n",
        "            st.write(f\"Matches for **{user_id}**:\")\n",
        "            sim_scores = similarity_matrix[idx]\n",
        "            sim_scores[idx] = -1\n",
        "            top_matches = sim_scores.argsort()[-2:][::-1]\n",
        "\n",
        "            for match_idx in top_matches:\n",
        "                st.write(f\"- {user_ids[match_idx]} (Similarity: {sim_scores[match_idx]:.2f})\")\n",
        "            st.write(\"---\")\n",
        "    else:\n",
        "        st.info(\"Upload at least 2 resumes to see matching results.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvx3YlCk_znC",
        "outputId": "54120de9-6f83-48a7-94e5-c5d22cc333d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matching.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile directions.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "def show_directions():\n",
        "    st.header(\"ğŸ—º Washroom Directions\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "     **Venue Layout**:\n",
        "    -  Ground Floor:\n",
        "        - ğŸš» Washroom near Registration Desk\n",
        "        - ğŸšº Womenâ€™s Washroom next to Conference Room A\n",
        "    -  First Floor:\n",
        "        - ğŸš» Common Washroom near Workshop Hall\n",
        "        - â™¿ Accessible Washroom at the stairway entrance\n",
        "\n",
        "    ğŸ”„ Ask any volunteer if you feel lost â€“ theyâ€™re happy to guide you!\n",
        "    \"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLHCK3XWe30L",
        "outputId": "7c362896-9bdc-44f8-bb90-a330dada89a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting directions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile recommendations.py\n",
        "import streamlit as st\n",
        "\n",
        "def show_recommendations():\n",
        "    st.header(\"ğŸ“Œ Session Recommendations\")\n",
        "    st.write(\"Based on your interests, here are some sessions we think youâ€™ll love:\")\n",
        "    recommendations = [\n",
        "        \"ğŸ¤– Hands On Workshop: Automation using Claude and MCP Server\",\n",
        "        \"ğŸ§  Agentic AI - Jitendra Gupta (Google Developer Expert)\",\n",
        "        \"ğŸ¤ Industry Application of AI: Building Multi AI Agents - Surendranath Reddy\",\n",
        "        \"ğŸ’¡ Workshop: Building Multi AI Agents - Mahidhar, NexusHub\"\n",
        "    ]\n",
        "    for session in recommendations:\n",
        "        st.markdown(f\"- {session}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhYjbDhcbVVG",
        "outputId": "ddd8e5ab-a375-45ce-a7b1-4dacd0ddaf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting recommendations.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile lunch_timer.py\n",
        "import streamlit as st\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def show_lunch_timer():\n",
        "    st.header(\"â±ï¸ Real-time Lunch Countdown\")\n",
        "\n",
        "    lunch_end_time = datetime(year=2025, month=5, day=18, hour=13, minute=0, second=0)\n",
        "\n",
        "\n",
        "    if datetime.now() > lunch_end_time:\n",
        "        st.success(\"ğŸ½ï¸ Lunch time is over!\")\n",
        "        return\n",
        "\n",
        "    placeholder = st.empty()\n",
        "\n",
        "    while True:\n",
        "        now = datetime.now()\n",
        "        remaining = lunch_end_time - now\n",
        "\n",
        "        if remaining.total_seconds() <= 0:\n",
        "            placeholder.success(\"ğŸ½ï¸ Lunch time is over!\")\n",
        "            break\n",
        "\n",
        "        mins, secs = divmod(int(remaining.total_seconds()), 60)\n",
        "        placeholder.markdown(f\"Time remaining for lunch: **{mins} minutes {secs} seconds**\")\n",
        "\n",
        "        time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJG642dIoebq",
        "outputId": "4c511a84-a716-4c33-d40d-df21bc64f145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting lunch_timer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feedback.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "feedback_list = []\n",
        "\n",
        "def show_feedback():\n",
        "    st.header(\"ğŸ“ Session Feedback\")\n",
        "\n",
        "    name = st.text_input(\"Your Name\")\n",
        "    session = st.selectbox(\"Session\", [\"Workshop 1\", \"Workshop 2\", \"Industry Talk\", \"Lunch\"])\n",
        "    rating = st.slider(\"Rate this session (1-5)\", 1, 5, 3)\n",
        "    comments = st.text_area(\"Additional Comments\")\n",
        "\n",
        "    if st.button(\"Submit Feedback\"):\n",
        "        if not name or not comments:\n",
        "            st.warning(\"Please fill in your name and comments.\")\n",
        "        else:\n",
        "            feedback = {\n",
        "                \"name\": name,\n",
        "                \"session\": session,\n",
        "                \"rating\": rating,\n",
        "                \"comments\": comments,\n",
        "            }\n",
        "            feedback_list.append(feedback)\n",
        "            st.success(\"Thank you for your feedback!\")\n",
        "\n",
        "    if feedback_list:\n",
        "        st.subheader(\"Previous Feedback\")\n",
        "        for fb in feedback_list:\n",
        "            st.markdown(f\"**{fb['name']}** on *{fb['session']}* rated: {fb['rating']}/5\")\n",
        "            st.write(fb['comments'])\n",
        "            st.write(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UWE5lCukrp7",
        "outputId": "d7c40c28-39dd-436b-8e02-e2c72e1c3727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting feedback.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit faiss-cpu sentence-transformers transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tkPwl-6ykSn",
        "outputId": "b8128986-d5b9-4e48-e614-775e35e42588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuzZZ9zX4mH",
        "outputId": "dbda6118-4057-49d7-d7b5-e8fc7ca5edaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250327->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rag_agent.py\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import pipeline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "generator = pipeline('text2text-generation', model='t5-small')\n",
        "\n",
        "embedding_dim = 384\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "documents = []\n",
        "\n",
        "def extract_text_from_pdf(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, max_length=500):\n",
        "    sentences = text.split('. ')\n",
        "    chunks = []\n",
        "    chunk = \"\"\n",
        "    for sent in sentences:\n",
        "        if len(chunk) + len(sent) < max_length:\n",
        "            chunk += sent + '. '\n",
        "        else:\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sent + '. '\n",
        "    if chunk:\n",
        "        chunks.append(chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "def add_document(file):\n",
        "    text = extract_text_from_pdf(file)\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = embedding_model.encode(chunks)\n",
        "    for emb, chunk in zip(embeddings, chunks):\n",
        "        index.add(np.array([emb]))\n",
        "        documents.append(chunk)\n",
        "\n",
        "def retrieve(query, top_k=3):\n",
        "    query_emb = embedding_model.encode([query])\n",
        "    D, I = index.search(np.array(query_emb), top_k)\n",
        "    results = [documents[i] for i in I[0] if i < len(documents)]\n",
        "    return results\n",
        "\n",
        "def generate_answer(retrieved_chunks, query):\n",
        "    context = \" \".join(retrieved_chunks)\n",
        "    input_text = f\"summarize: {context} question: {query}\"\n",
        "    output = generator(input_text, max_length=150)[0]['generated_text']\n",
        "    return output\n",
        "\n",
        "def show_rag_interface():\n",
        "    st.sidebar.header(\"ğŸ“š RAG Powered Event Assistant\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Upload\", type=['pdf'])\n",
        "    if uploaded_file is not None:\n",
        "        add_document(uploaded_file)\n",
        "        st.success(\"Document uploaded and indexed!\")\n",
        "\n",
        "    query = st.text_input(\"Ask anything:\")\n",
        "\n",
        "    if st.button(\"Get Answer\") and query:\n",
        "        if len(documents) == 0:\n",
        "            st.warning(\"Please upload notes first!\")\n",
        "        else:\n",
        "            retrieved = retrieve(query)\n",
        "            answer = generate_answer(retrieved, query)\n",
        "            st.markdown(\"**Answer:**\")\n",
        "            st.write(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myKlO9EKlnAz",
        "outputId": "8ff82673-ee44-4e4d-8b5c-f8fbb9732fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting rag_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ngrok authtoken 2xAMlsU2bxIRl7KmMZbHhz7gtnA_2gRj1UMqL13VFrSrKzbaT\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig3vcQ1uwV1y",
        "outputId": "2fffaa2a-a47a-42e2-a038-869cbba8be35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Kill previous tunnels\n",
        "!pkill streamlit\n",
        "\n",
        "# Open tunnel\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "\n",
        "print(f\"ğŸ”— Streamlit app URL: {public_url}\")\n",
        "\n",
        "# Run Streamlit app\n",
        "!streamlit run app.py &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtDMRE8Yw5XO",
        "outputId": "c7caa705-3898-41a2-b21b-b2c8c3725186"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”— Streamlit app URL: NgrokTunnel: \"https://bbb4-35-227-117-103.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.117.103:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-05-16 14:41:41.633126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747406501.719217   14392 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747406501.745401   14392 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Device set to use cpu\n",
            "2025-05-16 14:41:50.562 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "dT3ZQG5dW3yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktLrUTuwf_gg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}